<html>
  <head>
    <meta charset="UTF-8">
    <title>Audio samples from "Data-augmented cross-lingual synthesis in a teacher-student framework"</title>
    <link rel="stylesheet" type="text/css" href="../../stylesheet.css"/>
  </head>
  <body>
    <h1>
      Audio samples from "Data-augmented cross-lingual synthesis in a teacher-student framework"
    </h1>
    <p><b>Authors</b>: Marcel de Korte, Jaebok Kim, Aki Kunikoshi, Adaeze Adigwe, Esther Klabbers</p>
    <div><b>Abstract:</b> Cross-lingual synthesis can be defined as the task of letting a speaker generate fluent synthetic speech in another language. This is a challenging task, and resulting speech can suffer from reduced naturalness, accented speech, and/or loss of essential voice characteristics. Previous research shows that many models appear to have insufficient generalization capabilities to perform well on every of these cross-lingual aspects. To overcome these generalization problems, we propose to apply the teacher-student paradigm to cross-lingual synthesis. While a teacher model is commonly used to produce teacher forced data, we propose to also use the teacher model to produce augmented data of unseen speaker-language pairs, where its goal is to retain essential speaker characteristics. Both sets of data are then used for student model training, which is trained to retain the naturalness and prosodic variation present in the teacher forced data, while learning the speaker identity from the augmented data. Some modifications to the student model are proposed to make the separation of teacher forced and augmented data more straightforward. Results show that the proposed approach improves the retention of speaker characteristics in the speech, while retaining high levels of naturalness and prosodic variation.
      </div>
    <h2>Contents</h2>
    <div>Text: He did retain his sole set clarinet solo on Rockin' In Rhythm.</div>
    <table>
      <tbody>
        <tr><td>Reference:\t</td><td><audio controls=""><source src="../../audio/cross-lingual-data-augmentation/Polish_ref_sample_1.wav"></audio></td><td>Baseline:\t</td><td><audio controls=""><source src="../../audio/cross-lingual-data-augmentation/Polish_base_sample_1.wav"></audio></td><td>\tProposed:\t</td><td><audio controls=""><source src="../../audio/cross-lingual-data-augmentation/Polish_prop_sample_1.wav"></audio></td></tr>
        <tr><td>Reference:\t</td><td><audio controls=""><source src="../../audio/cross-lingual-data-augmentation/German_ref_sample_1.wav"></audio></td><td>Baseline:\t</td><td><audio controls=""><source src="../../audio/cross-lingual-data-augmentation/German_base_sample_1.wav"></audio></td><td>\tProposed:\t</td><td><audio controls=""><source src="../../audio/cross-lingual-data-augmentation/German_prop_sample_1.wav"></audio></td></tr>
        <tr><td>Reference:\t</td><td><audio controls=""><source src="../../audio/cross-lingual-data-augmentation/Swedish_ref_sample_1.wav"></audio></td><td>Baseline:\t</td><td><audio controls=""><source src="../../audio/cross-lingual-data-augmentation/Swedish_base_sample_1.wav"></audio></td><td>\tProposed:\t</td><td><audio controls=""><source src="../../audio/cross-lingual-data-augmentation/Swedish_prop_sample_1.wav"></audio></td></tr>
      </tbody>
    </table>
  </body>
</html>
